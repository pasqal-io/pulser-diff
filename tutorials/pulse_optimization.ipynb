{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pulser_diff.pulser import Sequence, Pulse, Register\n",
    "from pulser_diff.pulser.devices import MockDevice\n",
    "from pulser_diff.pulser.waveforms import BlackmanWaveform, RampWaveform\n",
    "\n",
    "from pulser_diff.model import QuantumModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy optimization problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create register\n",
    "reg = Register.rectangle(1, 2, spacing=8, prefix=\"q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequence and declare channels\n",
    "seq = Sequence(reg, MockDevice)\n",
    "seq.declare_channel(\"rydberg_global\", \"rydberg_global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pulse parameters\n",
    "omega = torch.tensor([5.0], requires_grad=True)\n",
    "area = torch.tensor([torch.pi], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare sequence variables\n",
    "omega_param = seq.declare_variable(\"omega\")\n",
    "area_param = seq.declare_variable(\"area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pulses\n",
    "pulse_const = Pulse.ConstantPulse(1000, omega_param, 0.0, 0.0)\n",
    "amp_wf = BlackmanWaveform(800, area_param)\n",
    "det_wf = RampWaveform(800, 5.0, 0.0)\n",
    "pulse_td = Pulse(amp_wf, det_wf, 0)\n",
    "\n",
    "# add pulses\n",
    "seq.add(pulse_const, \"rydberg_global\")\n",
    "seq.add(pulse_td, \"rydberg_global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trainable_params.area\n",
      "Parameter containing:\n",
      "tensor([3.1416], requires_grad=True)\n",
      "-------\n",
      "trainable_params.omega\n",
      "Parameter containing:\n",
      "tensor([5.], requires_grad=True)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# create quantum model from sequence\n",
    "trainable_params = {\"omega\": omega, \"area\": area}\n",
    "model = QuantumModel(seq, trainable_params, sampling_rate=0.5, solver=\"krylov\")\n",
    "\n",
    "# list trainable parameters of the model\n",
    "print()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial expectation value: tensor(-1.2782+0.j, grad_fn=<SelectBackward0>)\n",
      "\n",
      "loss: 0.605560\n",
      "loss: 0.433920\n",
      "loss: 0.252128\n",
      "loss: 0.119507\n",
      "loss: 0.050335\n",
      "loss: 0.020542\n",
      "loss: 0.008450\n",
      "loss: 0.003535\n",
      "loss: 0.001501\n",
      "loss: 0.000645\n",
      "loss: 0.000280\n",
      "loss: 0.000122\n",
      "loss: 0.000053\n",
      "loss: 0.000023\n",
      "loss: 0.000010\n",
      "loss: 0.000005\n",
      "loss: 0.000002\n",
      "loss: 0.000001\n",
      "loss: 0.000000\n",
      "loss: 0.000000\n",
      "\n",
      "Optimized expectation value: tensor(-0.5003+0.j, grad_fn=<SelectBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print initial expectation value as a result of simulating initial sequence\n",
    "_, init_exp_val = model.expectation()\n",
    "print(\"Initial expectation value:\", init_exp_val[-1])\n",
    "print()\n",
    "\n",
    "# optimize model parameters so that the final output expectation value matches the predefined value\n",
    "epochs = 20\n",
    "target_value = torch.tensor(-0.5)\n",
    "for t in range(epochs):\n",
    "    # calculate prediction and loss\n",
    "    evaluation_times, exp_val = model.expectation()\n",
    "    loss = loss_fn(exp_val.real[-1], target_value)\n",
    "\n",
    "    # backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # update sequence with changed pulse parameter values\n",
    "    model.update_sequence()\n",
    "\n",
    "    print(f\"loss: {loss:>7f}\")\n",
    "\n",
    "# print expectation value with optimized model\n",
    "_, init_exp_val = model.expectation()\n",
    "print()\n",
    "print(\"Optimized expectation value:\", init_exp_val[-1])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the optimized values of amplitude of the constant pulse `omega` and the area of the Blackman pulse `area`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trainable_params.area\n",
      "Parameter containing:\n",
      "tensor([2.7814], requires_grad=True)\n",
      "-------\n",
      "trainable_params.omega\n",
      "Parameter containing:\n",
      "tensor([4.4623], requires_grad=True)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of both parameters were optimized in order to minimize the provided loss function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qucint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
